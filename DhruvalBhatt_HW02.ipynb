{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perspectives in Computational Research: Homework 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "train_data = pd.read_csv('data/congress_train.csv', encoding = \"ISO-8859-1\")\n",
    "train_title = train_data['Title'].tolist()\n",
    "train_major = train_data['Major']\n",
    "\n",
    "# Validata Data\n",
    "val_data = pd.read_csv('data/congress_val.csv', encoding = \"ISO-8859-1\")\n",
    "val_title = val_data['Title'].tolist()\n",
    "val_major = val_data['Major']\n",
    "\n",
    "# Test Data\n",
    "test_data = pd.read_csv('data/congress_test.csv', encoding = \"ISO-8859-1\")\n",
    "test_title = test_data['Title'].tolist()\n",
    "test_major = test_data['Major']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=10000) #class restricting to 10000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "token.fit_on_texts(train_title)\n",
    "train_sequence = token.texts_to_sequences(train_title)\n",
    "train_x = pad_sequences(train_sequence, maxlen=100)\n",
    "train_y = to_categorical(train_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate Data\n",
    "token.fit_on_texts(val_title)\n",
    "val_sequence = token.texts_to_sequences(val_title)\n",
    "val_x = pad_sequences(val_sequence, maxlen=100)\n",
    "val_y = to_categorical(val_major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate Data\n",
    "token.fit_on_texts(test_title)\n",
    "test_sequence = token.texts_to_sequences(test_title)\n",
    "test_x = pad_sequences(test_sequence, maxlen=100)\n",
    "test_y = to_categorical(test_major)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "Reference: https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for Task Specific Embedding\n",
    "vocab_size = 10000\n",
    "pad_len = 100\n",
    "em_space = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "basic_model = Sequential()\n",
    "basic_model.add(Embedding(vocab_size, em_space, input_length=pad_length))\n",
    "basic_model.add(Flatten())\n",
    "basic_model.add(Dense(32, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "basic_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "#Fit and Store Model Val\n",
    "basic_metrics = basic_model.fit(train_x, train_y, epochs= 50, batch_size= 512, validation_data = (val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Accuracy and Loss from keras callback history\n",
    "basic_metrics = basic_metrics.history\n",
    "val_accuracy = basic_metrics['val_acc']\n",
    "val_loss = basic_metrics['val_loss']\n",
    "epochs = numpy.arange(1, len(val_accuracy)+1)\n",
    "\n",
    "#Plot Accuracy over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, val_accuracy)\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Accuracy over Range of Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "#Plot Loss over Epochs\n",
    "plt.clf()\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.margins(0)\n",
    "plt.title(\"Validation Loss over Range of Epochs\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
