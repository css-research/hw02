{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_Fan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcKvrEcaqrEj",
        "colab_type": "text"
      },
      "source": [
        "HW2\n",
        "Siyi Fan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-1GYD-fAo4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95e82f7c-9094-45be-d1b1-6388b3c58312"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thmaZZcfzisP",
        "colab_type": "code",
        "outputId": "d5d1429a-bbfc-4252-fbb4-3b09bb4aa1e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBlQrcKt3Fu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testfile = open('gdrive/My Drive/Colab Notebooks/data/congress_train.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = testfile.read()\n",
        "testfile.seek(0)\n",
        "testfile.write(text)\n",
        "testfile.close()\n",
        "\n",
        "trainfile = open('gdrive/My Drive/Colab Notebooks/data/congress_val.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = trainfile.read()\n",
        "trainfile.seek(0)\n",
        "trainfile.write(text)\n",
        "trainfile.close()\n",
        "\n",
        "valfile = open('gdrive/My Drive/Colab Notebooks/data/congress_test.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = valfile.read()\n",
        "valfile.seek(0)\n",
        "valfile.write(text)\n",
        "valfile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hS6PYfQAtBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_train.csv').dropna()\n",
        "valid_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_val.csv').dropna()\n",
        "test_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_test.csv').dropna()\n",
        "\n",
        "train_text = list(train_df['Title'])\n",
        "train_text = [str(i) for i in train_text]\n",
        "valid_text = list(valid_df['Title'])\n",
        "valid_text = [str(i) for i in valid_text]\n",
        "test_text = list(test_df['Title'])\n",
        "test_text = [str(i) for i in test_text]\n",
        "\n",
        "train_y = to_categorical(list(train_df['Major']))\n",
        "valid_y = to_categorical(list(valid_df['Major']))\n",
        "test_y = to_categorical(list(test_df['Major']))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_text)\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "valid_seq = tokenizer.texts_to_sequences(valid_text)\n",
        "\n",
        "train_x = pad_sequences(train_seq, maxlen=100)\n",
        "test_x = pad_sequences(test_seq, maxlen=100)\n",
        "valid_x = pad_sequences(valid_seq, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRDcorrT1MT2",
        "colab_type": "code",
        "outputId": "b43da911-bae4-438c-91a7-929aa1b43af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "ff = Sequential()\n",
        "ff.add(Embedding(10000, 20, input_length=100))\n",
        "ff.add(Flatten())\n",
        "ff.add(Dense(24, activation='softmax'))\n",
        "ff.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_ff = ff.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)\n",
        "\n",
        "loss_ff = result_ff.history['val_loss']\n",
        "acc_ff = result_ff.history['val_acc']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 5s 18us/step - loss: 1.9734 - acc: 0.4579 - val_loss: 1.1730 - val_acc: 0.7053\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.9087 - acc: 0.7638 - val_loss: 0.7804 - val_acc: 0.7948\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.6948 - acc: 0.8137 - val_loss: 0.6847 - val_acc: 0.8173\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.6143 - acc: 0.8336 - val_loss: 0.6432 - val_acc: 0.8321\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5675 - acc: 0.8456 - val_loss: 0.6177 - val_acc: 0.8363\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5349 - acc: 0.8540 - val_loss: 0.6050 - val_acc: 0.8379\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5100 - acc: 0.8598 - val_loss: 0.5939 - val_acc: 0.8426\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4899 - acc: 0.8651 - val_loss: 0.5904 - val_acc: 0.8415\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4732 - acc: 0.8695 - val_loss: 0.5858 - val_acc: 0.8451\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4584 - acc: 0.8734 - val_loss: 0.5849 - val_acc: 0.8475\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.4457 - acc: 0.8766 - val_loss: 0.5818 - val_acc: 0.8487\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4346 - acc: 0.8801 - val_loss: 0.5814 - val_acc: 0.8478\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4244 - acc: 0.8827 - val_loss: 0.5824 - val_acc: 0.8484\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4152 - acc: 0.8852 - val_loss: 0.5843 - val_acc: 0.8491\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4069 - acc: 0.8875 - val_loss: 0.5845 - val_acc: 0.8496\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3991 - acc: 0.8895 - val_loss: 0.5865 - val_acc: 0.8501\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3918 - acc: 0.8914 - val_loss: 0.5888 - val_acc: 0.8500\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3855 - acc: 0.8934 - val_loss: 0.5919 - val_acc: 0.8495\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3793 - acc: 0.8948 - val_loss: 0.5950 - val_acc: 0.8510\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3735 - acc: 0.8965 - val_loss: 0.5966 - val_acc: 0.8501\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3682 - acc: 0.8980 - val_loss: 0.6007 - val_acc: 0.8498\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3631 - acc: 0.8990 - val_loss: 0.6028 - val_acc: 0.8489\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3585 - acc: 0.9005 - val_loss: 0.6055 - val_acc: 0.8498\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3540 - acc: 0.9017 - val_loss: 0.6087 - val_acc: 0.8493\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3497 - acc: 0.9029 - val_loss: 0.6135 - val_acc: 0.8499\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3458 - acc: 0.9040 - val_loss: 0.6151 - val_acc: 0.8498\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3420 - acc: 0.9047 - val_loss: 0.6180 - val_acc: 0.8495\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3385 - acc: 0.9059 - val_loss: 0.6224 - val_acc: 0.8484\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3351 - acc: 0.9069 - val_loss: 0.6265 - val_acc: 0.8483\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3318 - acc: 0.9075 - val_loss: 0.6301 - val_acc: 0.8483\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3287 - acc: 0.9086 - val_loss: 0.6340 - val_acc: 0.8486\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3258 - acc: 0.9092 - val_loss: 0.6361 - val_acc: 0.8495\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3230 - acc: 0.9100 - val_loss: 0.6419 - val_acc: 0.8484\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3202 - acc: 0.9107 - val_loss: 0.6440 - val_acc: 0.8482\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3177 - acc: 0.9114 - val_loss: 0.6479 - val_acc: 0.8480\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3154 - acc: 0.9122 - val_loss: 0.6513 - val_acc: 0.8481\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3130 - acc: 0.9126 - val_loss: 0.6554 - val_acc: 0.8474\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3105 - acc: 0.9135 - val_loss: 0.6589 - val_acc: 0.8472\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3085 - acc: 0.9138 - val_loss: 0.6631 - val_acc: 0.8470\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3064 - acc: 0.9147 - val_loss: 0.6661 - val_acc: 0.8470\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3043 - acc: 0.9146 - val_loss: 0.6721 - val_acc: 0.8456\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.3025 - acc: 0.9153 - val_loss: 0.6737 - val_acc: 0.8464\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3007 - acc: 0.9160 - val_loss: 0.6770 - val_acc: 0.8466\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2987 - acc: 0.9166 - val_loss: 0.6812 - val_acc: 0.8460\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2969 - acc: 0.9168 - val_loss: 0.6847 - val_acc: 0.8457\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2952 - acc: 0.9173 - val_loss: 0.6876 - val_acc: 0.8453\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2937 - acc: 0.9175 - val_loss: 0.6914 - val_acc: 0.8457\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2922 - acc: 0.9183 - val_loss: 0.6952 - val_acc: 0.8450\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2905 - acc: 0.9188 - val_loss: 0.6990 - val_acc: 0.8450\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2891 - acc: 0.9190 - val_loss: 0.7026 - val_acc: 0.8447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZl0N9mM4Ink",
        "colab_type": "code",
        "outputId": "cd84248a-4360-4080-d43a-1192b07fcd89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "rnn = Sequential()\n",
        "rnn.add(Embedding(10000, 20, input_length=100))\n",
        "rnn.add(SimpleRNN(20))\n",
        "rnn.add(Dense(24, activation='softmax'))\n",
        "rnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn = rnn.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)\n",
        "\n",
        "loss_rnn1 = result_rnn.history['val_loss']\n",
        "acc_rnn1 = result_rnn.history['val_acc']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3b8163ea71a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG6jcfYVWodc",
        "colab_type": "code",
        "outputId": "41440eb1-292c-4dba-dffe-076bfdd24c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(Embedding(10000, 20, input_length=100))\n",
        "lstm.add(LSTM(20))\n",
        "lstm.add(Dense(24, activation='softmax'))\n",
        "lstm.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_lstm = lstm.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)\n",
        "\n",
        "loss_lstm = result_lstm.history['val_loss']\n",
        "acc_lstm = result_lstm.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 93s 335us/step - loss: 2.3717 - acc: 0.3007 - val_loss: 1.9072 - val_acc: 0.4351\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 93s 332us/step - loss: 1.5548 - acc: 0.5801 - val_loss: 1.4462 - val_acc: 0.5980\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 91s 327us/step - loss: 1.0952 - acc: 0.7242 - val_loss: 0.9864 - val_acc: 0.7578\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 92s 331us/step - loss: 0.8901 - acc: 0.7816 - val_loss: 0.9572 - val_acc: 0.7561\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 92s 329us/step - loss: 0.7855 - acc: 0.8047 - val_loss: 0.8197 - val_acc: 0.7930\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.7180 - acc: 0.8203 - val_loss: 0.7680 - val_acc: 0.8025\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.6677 - acc: 0.8310 - val_loss: 0.7223 - val_acc: 0.8154\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 95s 339us/step - loss: 0.6299 - acc: 0.8384 - val_loss: 0.6940 - val_acc: 0.8208\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 96s 345us/step - loss: 0.5979 - acc: 0.8446 - val_loss: 0.7016 - val_acc: 0.8144\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.5724 - acc: 0.8500 - val_loss: 0.6604 - val_acc: 0.8253\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 96s 344us/step - loss: 0.5514 - acc: 0.8540 - val_loss: 0.6186 - val_acc: 0.8353\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 98s 352us/step - loss: 0.5330 - acc: 0.8573 - val_loss: 0.6291 - val_acc: 0.8327\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 96s 346us/step - loss: 0.5178 - acc: 0.8605 - val_loss: 0.6038 - val_acc: 0.8377\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.5045 - acc: 0.8633 - val_loss: 0.6059 - val_acc: 0.8371\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.4935 - acc: 0.8656 - val_loss: 0.5865 - val_acc: 0.8435\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.4837 - acc: 0.8677 - val_loss: 0.5943 - val_acc: 0.8404\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.4756 - acc: 0.8695 - val_loss: 0.5825 - val_acc: 0.8438\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 97s 348us/step - loss: 0.4674 - acc: 0.8713 - val_loss: 0.5870 - val_acc: 0.8423\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 96s 346us/step - loss: 0.4603 - acc: 0.8736 - val_loss: 0.5756 - val_acc: 0.8457\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.4538 - acc: 0.8744 - val_loss: 0.5729 - val_acc: 0.8452\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 96s 344us/step - loss: 0.4477 - acc: 0.8760 - val_loss: 0.5675 - val_acc: 0.8472\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 96s 344us/step - loss: 0.4423 - acc: 0.8774 - val_loss: 0.5696 - val_acc: 0.8458\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 96s 344us/step - loss: 0.4371 - acc: 0.8785 - val_loss: 0.5645 - val_acc: 0.8476\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.4319 - acc: 0.8796 - val_loss: 0.5638 - val_acc: 0.8484\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 97s 349us/step - loss: 0.4269 - acc: 0.8816 - val_loss: 0.5712 - val_acc: 0.8473\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.4229 - acc: 0.8822 - val_loss: 0.5791 - val_acc: 0.8449\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 94s 336us/step - loss: 0.4181 - acc: 0.8835 - val_loss: 0.5498 - val_acc: 0.8527\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 98s 351us/step - loss: 0.4141 - acc: 0.8845 - val_loss: 0.5575 - val_acc: 0.8501\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.4104 - acc: 0.8856 - val_loss: 0.5641 - val_acc: 0.8490\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.4063 - acc: 0.8868 - val_loss: 0.5589 - val_acc: 0.8500\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 97s 346us/step - loss: 0.4029 - acc: 0.8872 - val_loss: 0.5494 - val_acc: 0.8535\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 97s 348us/step - loss: 0.3995 - acc: 0.8881 - val_loss: 0.5505 - val_acc: 0.8538\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 97s 349us/step - loss: 0.3963 - acc: 0.8891 - val_loss: 0.5520 - val_acc: 0.8532\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.3936 - acc: 0.8896 - val_loss: 0.5550 - val_acc: 0.8523\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.3904 - acc: 0.8906 - val_loss: 0.5546 - val_acc: 0.8523\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.3875 - acc: 0.8915 - val_loss: 0.5567 - val_acc: 0.8510\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.3847 - acc: 0.8921 - val_loss: 0.5507 - val_acc: 0.8539\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.3816 - acc: 0.8932 - val_loss: 0.5571 - val_acc: 0.8524\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.3789 - acc: 0.8934 - val_loss: 0.5484 - val_acc: 0.8544\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3762 - acc: 0.8944 - val_loss: 0.5506 - val_acc: 0.8547\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.3739 - acc: 0.8946 - val_loss: 0.5548 - val_acc: 0.8518\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 94s 339us/step - loss: 0.3716 - acc: 0.8953 - val_loss: 0.5504 - val_acc: 0.8553\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.3693 - acc: 0.8964 - val_loss: 0.5520 - val_acc: 0.8535\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.3670 - acc: 0.8969 - val_loss: 0.5858 - val_acc: 0.8451\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.3652 - acc: 0.8968 - val_loss: 0.5510 - val_acc: 0.8542\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.3628 - acc: 0.8977 - val_loss: 0.5557 - val_acc: 0.8548\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3609 - acc: 0.8981 - val_loss: 0.5519 - val_acc: 0.8545\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.3589 - acc: 0.8989 - val_loss: 0.5545 - val_acc: 0.8554\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.3568 - acc: 0.8995 - val_loss: 0.5519 - val_acc: 0.8553\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.3552 - acc: 0.9000 - val_loss: 0.5628 - val_acc: 0.8529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMZUKF-qQv94",
        "colab_type": "code",
        "outputId": "e7287091-3c32-4377-d29a-c7b758bcfdf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "gru = Sequential()\n",
        "gru.add(Embedding(10000, 20, input_length=100))\n",
        "gru.add(GRU(20))\n",
        "gru.add(Dense(24, activation='softmax'))\n",
        "gru.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_gru = gru.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)\n",
        "\n",
        "loss_gru = result_gru.history['val_loss']\n",
        "acc_gru = result_gru.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 81s 289us/step - loss: 2.4900 - acc: 0.2203 - val_loss: 2.0934 - val_acc: 0.3349\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 1.7419 - acc: 0.4938 - val_loss: 1.4758 - val_acc: 0.6001\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 1.2416 - acc: 0.6721 - val_loss: 1.0874 - val_acc: 0.7273\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.9438 - acc: 0.7678 - val_loss: 0.9183 - val_acc: 0.7755\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.8062 - acc: 0.8021 - val_loss: 0.8165 - val_acc: 0.7988\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 78s 278us/step - loss: 0.7330 - acc: 0.8171 - val_loss: 0.7737 - val_acc: 0.8072\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 77s 276us/step - loss: 0.6839 - acc: 0.8264 - val_loss: 0.7293 - val_acc: 0.8154\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 77s 276us/step - loss: 0.6473 - acc: 0.8343 - val_loss: 0.6984 - val_acc: 0.8231\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.6187 - acc: 0.8403 - val_loss: 0.6777 - val_acc: 0.8268\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 77s 275us/step - loss: 0.5946 - acc: 0.8457 - val_loss: 0.6612 - val_acc: 0.8302\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 77s 275us/step - loss: 0.5733 - acc: 0.8498 - val_loss: 0.6448 - val_acc: 0.8335\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.5554 - acc: 0.8533 - val_loss: 0.6273 - val_acc: 0.8379\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 78s 279us/step - loss: 0.5392 - acc: 0.8569 - val_loss: 0.6159 - val_acc: 0.8406\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 76s 273us/step - loss: 0.5250 - acc: 0.8598 - val_loss: 0.6126 - val_acc: 0.8398\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.5131 - acc: 0.8626 - val_loss: 0.6113 - val_acc: 0.8417\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 77s 275us/step - loss: 0.5020 - acc: 0.8647 - val_loss: 0.5958 - val_acc: 0.8438\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.4918 - acc: 0.8674 - val_loss: 0.6016 - val_acc: 0.8435\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.4826 - acc: 0.8700 - val_loss: 0.5846 - val_acc: 0.8472\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.4741 - acc: 0.8717 - val_loss: 0.5858 - val_acc: 0.8469\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 77s 275us/step - loss: 0.4663 - acc: 0.8738 - val_loss: 0.5888 - val_acc: 0.8457\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.4589 - acc: 0.8756 - val_loss: 0.5831 - val_acc: 0.8467\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.4519 - acc: 0.8771 - val_loss: 0.5733 - val_acc: 0.8498\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.4455 - acc: 0.8789 - val_loss: 0.5719 - val_acc: 0.8497\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 76s 274us/step - loss: 0.4391 - acc: 0.8802 - val_loss: 0.5712 - val_acc: 0.8498\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 81s 291us/step - loss: 0.4333 - acc: 0.8819 - val_loss: 0.5660 - val_acc: 0.8511\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 78s 282us/step - loss: 0.4277 - acc: 0.8830 - val_loss: 0.5658 - val_acc: 0.8506\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.4229 - acc: 0.8844 - val_loss: 0.5658 - val_acc: 0.8515\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.4178 - acc: 0.8860 - val_loss: 0.5639 - val_acc: 0.8510\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 81s 290us/step - loss: 0.4128 - acc: 0.8868 - val_loss: 0.5679 - val_acc: 0.8517\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 78s 280us/step - loss: 0.4088 - acc: 0.8883 - val_loss: 0.5676 - val_acc: 0.8516\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.4047 - acc: 0.8892 - val_loss: 0.5671 - val_acc: 0.8520\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.4005 - acc: 0.8899 - val_loss: 0.5638 - val_acc: 0.8515\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.3967 - acc: 0.8910 - val_loss: 0.5637 - val_acc: 0.8527\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.3929 - acc: 0.8924 - val_loss: 0.5657 - val_acc: 0.8532\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.3898 - acc: 0.8932 - val_loss: 0.5665 - val_acc: 0.8532\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 78s 280us/step - loss: 0.3865 - acc: 0.8942 - val_loss: 0.5699 - val_acc: 0.8512\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 80s 288us/step - loss: 0.3829 - acc: 0.8949 - val_loss: 0.5627 - val_acc: 0.8536\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.3802 - acc: 0.8958 - val_loss: 0.5643 - val_acc: 0.8546\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3772 - acc: 0.8967 - val_loss: 0.5653 - val_acc: 0.8540\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3746 - acc: 0.8971 - val_loss: 0.5724 - val_acc: 0.8526\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 81s 292us/step - loss: 0.3717 - acc: 0.8978 - val_loss: 0.5670 - val_acc: 0.8544\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.3688 - acc: 0.8985 - val_loss: 0.5657 - val_acc: 0.8551\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.3660 - acc: 0.8994 - val_loss: 0.5679 - val_acc: 0.8548\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3638 - acc: 0.9002 - val_loss: 0.5704 - val_acc: 0.8540\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 81s 292us/step - loss: 0.3613 - acc: 0.9007 - val_loss: 0.5669 - val_acc: 0.8553\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3589 - acc: 0.9015 - val_loss: 0.5716 - val_acc: 0.8545\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.3564 - acc: 0.9023 - val_loss: 0.5689 - val_acc: 0.8551\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.3543 - acc: 0.9026 - val_loss: 0.5780 - val_acc: 0.8532\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3518 - acc: 0.9033 - val_loss: 0.5720 - val_acc: 0.8537\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.3500 - acc: 0.9038 - val_loss: 0.5749 - val_acc: 0.8542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6olA85yWsyG",
        "colab_type": "code",
        "outputId": "50d77cf9-7090-4302-e22c-38ec33b971d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# 2-layers RNN \n",
        "rnn2 = Sequential()\n",
        "rnn2.add(Embedding(10000, 20, input_length=100))\n",
        "rnn2.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn2.add(SimpleRNN(20))\n",
        "rnn2.add(Dense(24, activation='softmax'))\n",
        "rnn2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn2 = rnn2.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)\n",
        "\n",
        "loss_rnn2 = result_rnn2.history['val_loss']\n",
        "acc_rnn2 = result_rnn2.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 66s 236us/step - loss: 2.3106 - acc: 0.3127 - val_loss: 1.8555 - val_acc: 0.4582\n",
            "Epoch 2/20\n",
            "278612/278612 [==============================] - 66s 236us/step - loss: 1.6404 - acc: 0.5289 - val_loss: 1.6324 - val_acc: 0.5301\n",
            "Epoch 3/20\n",
            "278612/278612 [==============================] - 65s 234us/step - loss: 1.3761 - acc: 0.6247 - val_loss: 1.2657 - val_acc: 0.6634\n",
            "Epoch 4/20\n",
            "278612/278612 [==============================] - 65s 233us/step - loss: 1.1331 - acc: 0.7027 - val_loss: 1.1685 - val_acc: 0.6905\n",
            "Epoch 5/20\n",
            "278612/278612 [==============================] - 64s 230us/step - loss: 0.9780 - acc: 0.7480 - val_loss: 1.0040 - val_acc: 0.7429\n",
            "Epoch 6/20\n",
            "278612/278612 [==============================] - 65s 232us/step - loss: 0.8725 - acc: 0.7777 - val_loss: 0.9109 - val_acc: 0.7715\n",
            "Epoch 7/20\n",
            "278612/278612 [==============================] - 66s 236us/step - loss: 0.8012 - acc: 0.7959 - val_loss: 0.8879 - val_acc: 0.7733\n",
            "Epoch 8/20\n",
            "278612/278612 [==============================] - 65s 232us/step - loss: 0.7523 - acc: 0.8085 - val_loss: 0.9481 - val_acc: 0.7554\n",
            "Epoch 9/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.7140 - acc: 0.8184 - val_loss: 0.8492 - val_acc: 0.7828\n",
            "Epoch 10/20\n",
            "278612/278612 [==============================] - 64s 228us/step - loss: 0.6848 - acc: 0.8261 - val_loss: 0.8207 - val_acc: 0.7934\n",
            "Epoch 11/20\n",
            "278612/278612 [==============================] - 66s 236us/step - loss: 0.6606 - acc: 0.8324 - val_loss: 0.8140 - val_acc: 0.7935\n",
            "Epoch 12/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.6410 - acc: 0.8367 - val_loss: 0.8605 - val_acc: 0.7796\n",
            "Epoch 13/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.6243 - acc: 0.8412 - val_loss: 0.8061 - val_acc: 0.7959\n",
            "Epoch 14/20\n",
            "278612/278612 [==============================] - 64s 230us/step - loss: 0.6092 - acc: 0.8448 - val_loss: 0.8105 - val_acc: 0.7941\n",
            "Epoch 15/20\n",
            "278612/278612 [==============================] - 63s 227us/step - loss: 0.5969 - acc: 0.8475 - val_loss: 0.7896 - val_acc: 0.8015\n",
            "Epoch 16/20\n",
            "278612/278612 [==============================] - 66s 235us/step - loss: 0.5838 - acc: 0.8503 - val_loss: 0.7651 - val_acc: 0.8095\n",
            "Epoch 17/20\n",
            "278612/278612 [==============================] - 64s 229us/step - loss: 0.5730 - acc: 0.8537 - val_loss: 0.7978 - val_acc: 0.8010\n",
            "Epoch 18/20\n",
            "278612/278612 [==============================] - 64s 229us/step - loss: 0.5634 - acc: 0.8556 - val_loss: 0.7939 - val_acc: 0.8001\n",
            "Epoch 19/20\n",
            "278612/278612 [==============================] - 64s 229us/step - loss: 0.5555 - acc: 0.8579 - val_loss: 0.8081 - val_acc: 0.7963\n",
            "Epoch 20/20\n",
            "278612/278612 [==============================] - 63s 226us/step - loss: 0.5465 - acc: 0.8605 - val_loss: 0.7887 - val_acc: 0.8027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4my1qGI4wxM",
        "colab_type": "code",
        "outputId": "7978250e-6529-4f46-9efe-5d3bd86979d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# 4-layers RNN \n",
        "rnn4 = Sequential()\n",
        "rnn4.add(Embedding(10000, 20, input_length=100))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20))\n",
        "rnn4.add(Dense(24, activation='softmax'))\n",
        "rnn4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn4 = rnn4.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)\n",
        "\n",
        "loss_rnn4 = result_rnn4.history['val_loss']\n",
        "acc_rnn4 = result_rnn4.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 126s 453us/step - loss: 2.0618 - acc: 0.3925 - val_loss: 1.4800 - val_acc: 0.5790\n",
            "Epoch 2/20\n",
            "278612/278612 [==============================] - 124s 446us/step - loss: 1.2941 - acc: 0.6497 - val_loss: 1.2549 - val_acc: 0.6520\n",
            "Epoch 3/20\n",
            "278612/278612 [==============================] - 125s 449us/step - loss: 1.0674 - acc: 0.7207 - val_loss: 1.0578 - val_acc: 0.7228\n",
            "Epoch 4/20\n",
            "278612/278612 [==============================] - 124s 444us/step - loss: 0.9600 - acc: 0.7517 - val_loss: 1.1054 - val_acc: 0.7031\n",
            "Epoch 5/20\n",
            "278612/278612 [==============================] - 124s 446us/step - loss: 0.8931 - acc: 0.7694 - val_loss: 1.0185 - val_acc: 0.7299\n",
            "Epoch 6/20\n",
            "278612/278612 [==============================] - 124s 444us/step - loss: 0.8517 - acc: 0.7804 - val_loss: 0.9297 - val_acc: 0.7591\n",
            "Epoch 7/20\n",
            "278612/278612 [==============================] - 124s 445us/step - loss: 0.8133 - acc: 0.7896 - val_loss: 1.0260 - val_acc: 0.7333\n",
            "Epoch 8/20\n",
            "278612/278612 [==============================] - 125s 450us/step - loss: 0.7805 - acc: 0.7989 - val_loss: 0.9301 - val_acc: 0.7572\n",
            "Epoch 9/20\n",
            "278612/278612 [==============================] - 121s 435us/step - loss: 0.7591 - acc: 0.8045 - val_loss: 0.9359 - val_acc: 0.7544\n",
            "Epoch 10/20\n",
            "278612/278612 [==============================] - 124s 447us/step - loss: 0.7265 - acc: 0.8124 - val_loss: 0.9291 - val_acc: 0.7565\n",
            "Epoch 11/20\n",
            "278612/278612 [==============================] - 121s 436us/step - loss: 0.7048 - acc: 0.8178 - val_loss: 0.8392 - val_acc: 0.7843\n",
            "Epoch 12/20\n",
            "278612/278612 [==============================] - 124s 446us/step - loss: 0.6851 - acc: 0.8228 - val_loss: 0.8916 - val_acc: 0.7681\n",
            "Epoch 13/20\n",
            "278612/278612 [==============================] - 124s 446us/step - loss: 0.6634 - acc: 0.8278 - val_loss: 0.8624 - val_acc: 0.7783\n",
            "Epoch 14/20\n",
            "278612/278612 [==============================] - 124s 446us/step - loss: 0.6731 - acc: 0.8270 - val_loss: 0.8331 - val_acc: 0.7868\n",
            "Epoch 15/20\n",
            "278612/278612 [==============================] - 127s 456us/step - loss: 0.6325 - acc: 0.8362 - val_loss: 0.7951 - val_acc: 0.7976\n",
            "Epoch 16/20\n",
            "278612/278612 [==============================] - 126s 452us/step - loss: 0.6339 - acc: 0.8359 - val_loss: 0.7953 - val_acc: 0.7988\n",
            "Epoch 17/20\n",
            "278612/278612 [==============================] - 127s 456us/step - loss: 0.6103 - acc: 0.8416 - val_loss: 0.8340 - val_acc: 0.7847\n",
            "Epoch 18/20\n",
            "278612/278612 [==============================] - 127s 456us/step - loss: 0.5980 - acc: 0.8445 - val_loss: 0.7845 - val_acc: 0.8020\n",
            "Epoch 19/20\n",
            "278612/278612 [==============================] - 127s 454us/step - loss: 0.5938 - acc: 0.8455 - val_loss: 0.7824 - val_acc: 0.8024\n",
            "Epoch 20/20\n",
            "278612/278612 [==============================] - 127s 454us/step - loss: 0.6020 - acc: 0.8447 - val_loss: 0.7840 - val_acc: 0.7996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ve8ratR45xe",
        "colab_type": "code",
        "outputId": "4d1f209f-eeb8-41fe-8bbb-a4c89c8d3ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "rnn_drop = Sequential()\n",
        "rnn_drop.add(Embedding(10000, 20, input_length=100))\n",
        "rnn_drop.add(SimpleRNN(20, dropout=0.3))\n",
        "rnn_drop.add(Dense(24, activation='softmax'))\n",
        "rnn_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn_drop = rnn_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)\n",
        "\n",
        "loss_rnn_drop = result_rnn_drop.history['val_loss']\n",
        "acc_rnn_drop = result_rnn_drop.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 36s 128us/step - loss: 2.3990 - acc: 0.3010 - val_loss: 1.9194 - val_acc: 0.4136\n",
            "Epoch 2/20\n",
            "278612/278612 [==============================] - 35s 126us/step - loss: 1.7973 - acc: 0.4669 - val_loss: 1.5845 - val_acc: 0.5542\n",
            "Epoch 3/20\n",
            "278612/278612 [==============================] - 36s 128us/step - loss: 1.5089 - acc: 0.5726 - val_loss: 1.3708 - val_acc: 0.6339\n",
            "Epoch 4/20\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 1.3348 - acc: 0.6329 - val_loss: 1.2039 - val_acc: 0.6897\n",
            "Epoch 5/20\n",
            "278612/278612 [==============================] - 37s 132us/step - loss: 1.2057 - acc: 0.6748 - val_loss: 1.1245 - val_acc: 0.7163\n",
            "Epoch 6/20\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 1.1173 - acc: 0.7019 - val_loss: 1.0089 - val_acc: 0.7415\n",
            "Epoch 7/20\n",
            "278612/278612 [==============================] - 37s 132us/step - loss: 1.0476 - acc: 0.7229 - val_loss: 0.9714 - val_acc: 0.7537\n",
            "Epoch 8/20\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 0.9977 - acc: 0.7396 - val_loss: 0.9261 - val_acc: 0.7628\n",
            "Epoch 9/20\n",
            "278612/278612 [==============================] - 36s 129us/step - loss: 0.9572 - acc: 0.7504 - val_loss: 0.9038 - val_acc: 0.7762\n",
            "Epoch 10/20\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 0.9307 - acc: 0.7595 - val_loss: 0.8663 - val_acc: 0.7855\n",
            "Epoch 11/20\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 0.9044 - acc: 0.7666 - val_loss: 0.9383 - val_acc: 0.7703\n",
            "Epoch 12/20\n",
            "278612/278612 [==============================] - 36s 129us/step - loss: 0.8901 - acc: 0.7711 - val_loss: 0.8573 - val_acc: 0.7930\n",
            "Epoch 13/20\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.8720 - acc: 0.7769 - val_loss: 0.8803 - val_acc: 0.7885\n",
            "Epoch 14/20\n",
            "278612/278612 [==============================] - 36s 131us/step - loss: 0.8607 - acc: 0.7791 - val_loss: 0.8463 - val_acc: 0.7918\n",
            "Epoch 15/20\n",
            "278612/278612 [==============================] - 34s 123us/step - loss: 0.8501 - acc: 0.7822 - val_loss: 0.9239 - val_acc: 0.7666\n",
            "Epoch 16/20\n",
            "278612/278612 [==============================] - 37s 133us/step - loss: 0.8448 - acc: 0.7833 - val_loss: 0.8253 - val_acc: 0.7981\n",
            "Epoch 17/20\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.8337 - acc: 0.7869 - val_loss: 0.8271 - val_acc: 0.7972\n",
            "Epoch 18/20\n",
            "278612/278612 [==============================] - 35s 124us/step - loss: 0.8267 - acc: 0.7882 - val_loss: 0.8420 - val_acc: 0.7970\n",
            "Epoch 19/20\n",
            "278612/278612 [==============================] - 35s 124us/step - loss: 0.8228 - acc: 0.7890 - val_loss: 0.8249 - val_acc: 0.7966\n",
            "Epoch 20/20\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.8146 - acc: 0.7913 - val_loss: 0.7962 - val_acc: 0.8031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3PQ9App4_C6",
        "colab_type": "code",
        "outputId": "afecaab1-8604-441b-bc3d-2aed5a307627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "lstm_drop = Sequential()\n",
        "lstm_drop.add(Embedding(10000, 20, input_length=100))\n",
        "lstm_drop.add(LSTM(20, dropout=0.3))\n",
        "lstm_drop.add(Dense(24, activation='softmax'))\n",
        "lstm_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_lstm_drop = lstm_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)\n",
        "\n",
        "loss_lstm_drop = result_lstm_drop.history['val_loss']\n",
        "acc_lstm_drop = result_lstm_drop.history['val_acc']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 104s 375us/step - loss: 2.4260 - acc: 0.2720 - val_loss: 1.8861 - val_acc: 0.4765\n",
            "Epoch 2/20\n",
            "278612/278612 [==============================] - 101s 363us/step - loss: 1.6382 - acc: 0.5447 - val_loss: 1.3902 - val_acc: 0.6229\n",
            "Epoch 3/20\n",
            "278612/278612 [==============================] - 103s 369us/step - loss: 1.2306 - acc: 0.6754 - val_loss: 1.0751 - val_acc: 0.7274\n",
            "Epoch 4/20\n",
            "278612/278612 [==============================] - 103s 371us/step - loss: 1.0194 - acc: 0.7414 - val_loss: 0.9222 - val_acc: 0.7726\n",
            "Epoch 5/20\n",
            "278612/278612 [==============================] - 102s 365us/step - loss: 0.8921 - acc: 0.7769 - val_loss: 0.8055 - val_acc: 0.8008\n",
            "Epoch 6/20\n",
            "278612/278612 [==============================] - 102s 367us/step - loss: 0.8038 - acc: 0.7978 - val_loss: 0.7790 - val_acc: 0.8051\n",
            "Epoch 7/20\n",
            "278612/278612 [==============================] - 104s 373us/step - loss: 0.7440 - acc: 0.8104 - val_loss: 0.7211 - val_acc: 0.8145\n",
            "Epoch 8/20\n",
            "278612/278612 [==============================] - 100s 360us/step - loss: 0.7006 - acc: 0.8199 - val_loss: 0.6759 - val_acc: 0.8263\n",
            "Epoch 9/20\n",
            "278612/278612 [==============================] - 101s 363us/step - loss: 0.6675 - acc: 0.8261 - val_loss: 0.6669 - val_acc: 0.8294\n",
            "Epoch 10/20\n",
            "278612/278612 [==============================] - 102s 365us/step - loss: 0.6431 - acc: 0.8307 - val_loss: 0.6373 - val_acc: 0.8334\n",
            "Epoch 11/20\n",
            "278612/278612 [==============================] - 101s 364us/step - loss: 0.6236 - acc: 0.8353 - val_loss: 0.6284 - val_acc: 0.8360\n",
            "Epoch 12/20\n",
            "278612/278612 [==============================] - 101s 364us/step - loss: 0.6067 - acc: 0.8383 - val_loss: 0.6199 - val_acc: 0.8384\n",
            "Epoch 13/20\n",
            "278612/278612 [==============================] - 102s 368us/step - loss: 0.5946 - acc: 0.8413 - val_loss: 0.6092 - val_acc: 0.8393\n",
            "Epoch 14/20\n",
            "278612/278612 [==============================] - 101s 364us/step - loss: 0.5830 - acc: 0.8432 - val_loss: 0.6025 - val_acc: 0.8404\n",
            "Epoch 15/20\n",
            "278612/278612 [==============================] - 101s 363us/step - loss: 0.5741 - acc: 0.8450 - val_loss: 0.5931 - val_acc: 0.8435\n",
            "Epoch 16/20\n",
            "278612/278612 [==============================] - 102s 365us/step - loss: 0.5648 - acc: 0.8470 - val_loss: 0.5949 - val_acc: 0.8417\n",
            "Epoch 17/20\n",
            "278612/278612 [==============================] - 100s 358us/step - loss: 0.5589 - acc: 0.8480 - val_loss: 0.5794 - val_acc: 0.8459\n",
            "Epoch 18/20\n",
            "278612/278612 [==============================] - 103s 369us/step - loss: 0.5523 - acc: 0.8496 - val_loss: 0.5828 - val_acc: 0.8446\n",
            "Epoch 19/20\n",
            "278612/278612 [==============================] - 102s 365us/step - loss: 0.5476 - acc: 0.8508 - val_loss: 0.5884 - val_acc: 0.8417\n",
            "Epoch 20/20\n",
            "278612/278612 [==============================] - 98s 351us/step - loss: 0.5414 - acc: 0.8519 - val_loss: 0.5735 - val_acc: 0.8450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWMfH-437rNp",
        "colab_type": "code",
        "outputId": "bf983400-939e-4d59-9de0-678c2e3d0abb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "gru_drop = Sequential()\n",
        "gru_drop.add(Embedding(10000, 20, input_length=100))\n",
        "gru_drop.add(GRU(20, dropout=0.3))\n",
        "gru_drop.add(Dense(24, activation='softmax'))\n",
        "gru_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_gru_drop = gru_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)\n",
        "\n",
        "loss_gru_drop = result_gru_drop.history['val_loss']\n",
        "acc_gru_drop = result_gru_drop.history['val_acc']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7c2d5c911e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgru_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgru_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult_gru_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mloss_gru_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_gru_drop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYl56OLgtYKT",
        "colab_type": "code",
        "outputId": "10c13f4d-e3c2-40c4-c8da-e1804d1a2d2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "plt.plot(loss_ff)\n",
        "plt.plot(loss_rnn1)\n",
        "plt.plot(loss_lstm)\n",
        "plt.plot(loss_gru)\n",
        "plt.plot(loss_rnn2)\n",
        "plt.plot(loss_rnn4)\n",
        "plt.plot(loss_rnn_drop)\n",
        "plt.plot(loss_lstm_drop)\n",
        "plt.plot(loss_gru_drop)\n",
        "plt.legend(['ff', 'rnn_1layer', 'lstm', 'gru', 'rnn_2layers', 'rnn_4layers', 'rnn_dropout', 'lstm_dropout', 'gru_dropout'])\n",
        "plt.title('Comparing validation set loss over the epochs')\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6b5f916a7a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_rnn1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_lstm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gru\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_rnn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_ff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__y1VxRG5EFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(acc_ff)\n",
        "plt.plot(acc_rnn1)\n",
        "plt.plot(acc_lstm)\n",
        "plt.plot(acc_gru)\n",
        "plt.plot(acc_rnn2)\n",
        "plt.plot(acc_rnn4)\n",
        "plt.plot(acc_rnn_drop)\n",
        "plt.plot(acc_lstm_drop)\n",
        "plt.plot(acc_gru_drop)\n",
        "plt.legend(['ff', 'rnn_1layer', 'lstm', 'gru', 'rnn_2layers', 'rnn_4layers', 'rnn_dropout', 'lstm_dropout', 'gru_dropout'])\n",
        "plt.title(\"Comparing validation set accuracy over the epochs\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPoGkfxJ9ESt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru.evaluate(test_x, test_y)\n",
        "lstm.evaluate(test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}