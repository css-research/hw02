{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_Fan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcKvrEcaqrEj",
        "colab_type": "text"
      },
      "source": [
        "HW2\n",
        "Siyi Fan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-1GYD-fAo4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb1bf0c9-cd60-4531-de43-c803fe75e9a0"
      },
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UweJ6G0vAq4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thmaZZcfzisP",
        "colab_type": "code",
        "outputId": "bc1b5924-c3aa-4af2-82f6-ca614faba5b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBlQrcKt3Fu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testfile = open('gdrive/My Drive/Colab Notebooks/data/congress_train.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = testfile.read()\n",
        "testfile.seek(0)\n",
        "testfile.write(text)\n",
        "testfile.close()\n",
        "\n",
        "trainfile = open('gdrive/My Drive/Colab Notebooks/data/congress_val.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = trainfile.read()\n",
        "trainfile.seek(0)\n",
        "trainfile.write(text)\n",
        "trainfile.close()\n",
        "\n",
        "valfile = open('gdrive/My Drive/Colab Notebooks/data/congress_test.csv', \"r+\",encoding='utf-8', errors='ignore')\n",
        "text = valfile.read()\n",
        "valfile.seek(0)\n",
        "valfile.write(text)\n",
        "valfile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hS6PYfQAtBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_train.csv').dropna()\n",
        "valid_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_val.csv').dropna()\n",
        "test_df = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/congress_test.csv').dropna()\n",
        "\n",
        "train_text = list(train_df['Title'])\n",
        "train_text = [str(i) for i in train_text]\n",
        "valid_text = list(valid_df['Title'])\n",
        "valid_text = [str(i) for i in valid_text]\n",
        "test_text = list(test_df['Title'])\n",
        "test_text = [str(i) for i in test_text]\n",
        "\n",
        "train_y = to_categorical(list(train_df['Major']))\n",
        "valid_y = to_categorical(list(valid_df['Major']))\n",
        "test_y = to_categorical(list(test_df['Major']))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_text)\n",
        "\n",
        "train_seq = tokenizer.texts_to_sequences(train_text)\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "valid_seq = tokenizer.texts_to_sequences(valid_text)\n",
        "\n",
        "train_x = pad_sequences(train_seq, maxlen=100)\n",
        "test_x = pad_sequences(test_seq, maxlen=100)\n",
        "valid_x = pad_sequences(valid_seq, maxlen=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRDcorrT1MT2",
        "colab_type": "code",
        "outputId": "7cbb4450-32b2-48f4-ac90-51ac98fb6145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1856
        }
      },
      "source": [
        "ff = Sequential()\n",
        "ff.add(Embedding(10000, 20, input_length=100))\n",
        "ff.add(Flatten())\n",
        "ff.add(Dense(24, activation='softmax'))\n",
        "ff.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_ff = ff.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 4s 16us/step - loss: 1.9484 - acc: 0.4674 - val_loss: 1.1708 - val_acc: 0.6992\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.9091 - acc: 0.7636 - val_loss: 0.7859 - val_acc: 0.7913\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.6947 - acc: 0.8134 - val_loss: 0.6870 - val_acc: 0.8183\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.6148 - acc: 0.8333 - val_loss: 0.6440 - val_acc: 0.8292\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5685 - acc: 0.8451 - val_loss: 0.6197 - val_acc: 0.8353\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5360 - acc: 0.8533 - val_loss: 0.6047 - val_acc: 0.8391\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.5113 - acc: 0.8598 - val_loss: 0.5971 - val_acc: 0.8406\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4911 - acc: 0.8651 - val_loss: 0.5908 - val_acc: 0.8431\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.4742 - acc: 0.8691 - val_loss: 0.5848 - val_acc: 0.8460\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.4596 - acc: 0.8732 - val_loss: 0.5837 - val_acc: 0.8465\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.4469 - acc: 0.8766 - val_loss: 0.5823 - val_acc: 0.8475\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.4355 - acc: 0.8796 - val_loss: 0.5804 - val_acc: 0.8484\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4253 - acc: 0.8827 - val_loss: 0.5812 - val_acc: 0.8486\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4162 - acc: 0.8850 - val_loss: 0.5823 - val_acc: 0.8476\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.4077 - acc: 0.8875 - val_loss: 0.5846 - val_acc: 0.8487\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3999 - acc: 0.8897 - val_loss: 0.5852 - val_acc: 0.8488\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3929 - acc: 0.8917 - val_loss: 0.5876 - val_acc: 0.8503\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3861 - acc: 0.8933 - val_loss: 0.5894 - val_acc: 0.8490\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3799 - acc: 0.8948 - val_loss: 0.5912 - val_acc: 0.8500\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3742 - acc: 0.8966 - val_loss: 0.5948 - val_acc: 0.8491\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3688 - acc: 0.8982 - val_loss: 0.5965 - val_acc: 0.8499\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3638 - acc: 0.8995 - val_loss: 0.6001 - val_acc: 0.8491\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3592 - acc: 0.9005 - val_loss: 0.6035 - val_acc: 0.8486\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3548 - acc: 0.9016 - val_loss: 0.6061 - val_acc: 0.8498\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3506 - acc: 0.9029 - val_loss: 0.6101 - val_acc: 0.8494\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3465 - acc: 0.9039 - val_loss: 0.6146 - val_acc: 0.8492\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3429 - acc: 0.9050 - val_loss: 0.6159 - val_acc: 0.8494\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3393 - acc: 0.9056 - val_loss: 0.6195 - val_acc: 0.8489\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3359 - acc: 0.9069 - val_loss: 0.6230 - val_acc: 0.8490\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3328 - acc: 0.9077 - val_loss: 0.6259 - val_acc: 0.8478\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3297 - acc: 0.9081 - val_loss: 0.6298 - val_acc: 0.8481\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3267 - acc: 0.9091 - val_loss: 0.6330 - val_acc: 0.8481\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3239 - acc: 0.9100 - val_loss: 0.6371 - val_acc: 0.8481\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3214 - acc: 0.9105 - val_loss: 0.6413 - val_acc: 0.8472\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3187 - acc: 0.9112 - val_loss: 0.6437 - val_acc: 0.8478\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3162 - acc: 0.9120 - val_loss: 0.6484 - val_acc: 0.8470\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3138 - acc: 0.9127 - val_loss: 0.6535 - val_acc: 0.8469\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3116 - acc: 0.9129 - val_loss: 0.6550 - val_acc: 0.8468\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3093 - acc: 0.9136 - val_loss: 0.6583 - val_acc: 0.8469\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3072 - acc: 0.9142 - val_loss: 0.6626 - val_acc: 0.8465\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3052 - acc: 0.9147 - val_loss: 0.6652 - val_acc: 0.8467\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3033 - acc: 0.9152 - val_loss: 0.6710 - val_acc: 0.8459\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.3014 - acc: 0.9160 - val_loss: 0.6727 - val_acc: 0.8464\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2997 - acc: 0.9161 - val_loss: 0.6771 - val_acc: 0.8456\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2978 - acc: 0.9164 - val_loss: 0.6798 - val_acc: 0.8462\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2961 - acc: 0.9172 - val_loss: 0.6849 - val_acc: 0.8445\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2944 - acc: 0.9176 - val_loss: 0.6871 - val_acc: 0.8453\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 2s 7us/step - loss: 0.2929 - acc: 0.9179 - val_loss: 0.6910 - val_acc: 0.8446\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.2914 - acc: 0.9185 - val_loss: 0.6942 - val_acc: 0.8449\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 2s 8us/step - loss: 0.2897 - acc: 0.9190 - val_loss: 0.6995 - val_acc: 0.8444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZl0N9mM4Ink",
        "colab_type": "code",
        "outputId": "233c5b04-12f8-41ab-869e-e807ba0cd098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "rnn = Sequential()\n",
        "rnn.add(Embedding(10000, 20, input_length=100))\n",
        "rnn.add(SimpleRNN(20))\n",
        "rnn.add(Dense(24, activation='softmax'))\n",
        "rnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn = rnn.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 34s 123us/step - loss: 2.3469 - acc: 0.2998 - val_loss: 1.8628 - val_acc: 0.4471\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 31s 113us/step - loss: 1.7097 - acc: 0.4981 - val_loss: 1.6025 - val_acc: 0.5442\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 33s 118us/step - loss: 1.4429 - acc: 0.6000 - val_loss: 1.3399 - val_acc: 0.6422\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 32s 117us/step - loss: 1.2525 - acc: 0.6644 - val_loss: 1.2205 - val_acc: 0.6768\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 32s 114us/step - loss: 1.1267 - acc: 0.7035 - val_loss: 1.1758 - val_acc: 0.6917\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 33s 120us/step - loss: 1.0271 - acc: 0.7329 - val_loss: 1.0574 - val_acc: 0.7281\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 32s 117us/step - loss: 0.9554 - acc: 0.7546 - val_loss: 1.0801 - val_acc: 0.7179\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 35s 124us/step - loss: 0.9012 - acc: 0.7701 - val_loss: 0.9968 - val_acc: 0.7482\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 32s 114us/step - loss: 0.8606 - acc: 0.7807 - val_loss: 1.0201 - val_acc: 0.7333\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 33s 119us/step - loss: 0.8244 - acc: 0.7903 - val_loss: 0.9749 - val_acc: 0.7503\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.7900 - acc: 0.7997 - val_loss: 0.9281 - val_acc: 0.7666\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 32s 115us/step - loss: 0.7613 - acc: 0.8064 - val_loss: 0.9307 - val_acc: 0.7636\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.7334 - acc: 0.8135 - val_loss: 0.8693 - val_acc: 0.7780\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 33s 118us/step - loss: 0.7126 - acc: 0.8191 - val_loss: 0.8844 - val_acc: 0.7755\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 33s 117us/step - loss: 0.6926 - acc: 0.8241 - val_loss: 0.8865 - val_acc: 0.7719\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.6770 - acc: 0.8276 - val_loss: 0.8228 - val_acc: 0.7945\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 34s 123us/step - loss: 0.6625 - acc: 0.8315 - val_loss: 0.8634 - val_acc: 0.7797\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 34s 123us/step - loss: 0.6518 - acc: 0.8341 - val_loss: 0.8040 - val_acc: 0.7970\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 33s 120us/step - loss: 0.6379 - acc: 0.8379 - val_loss: 0.8626 - val_acc: 0.7824\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.6308 - acc: 0.8390 - val_loss: 0.8222 - val_acc: 0.7949\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 32s 116us/step - loss: 0.6343 - acc: 0.8382 - val_loss: 0.8505 - val_acc: 0.7875\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 32s 115us/step - loss: 0.6089 - acc: 0.8448 - val_loss: 0.8963 - val_acc: 0.7671\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 34s 120us/step - loss: 0.6003 - acc: 0.8466 - val_loss: 0.8320 - val_acc: 0.7889\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 32s 116us/step - loss: 0.5953 - acc: 0.8489 - val_loss: 0.8688 - val_acc: 0.7803\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 33s 120us/step - loss: 0.5865 - acc: 0.8510 - val_loss: 0.7894 - val_acc: 0.8021\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5948 - acc: 0.8480 - val_loss: 0.8207 - val_acc: 0.7927\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 32s 115us/step - loss: 0.5800 - acc: 0.8520 - val_loss: 0.7730 - val_acc: 0.8080\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 38s 136us/step - loss: 0.5677 - acc: 0.8555 - val_loss: 0.7819 - val_acc: 0.8082\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.5615 - acc: 0.8568 - val_loss: 0.8140 - val_acc: 0.7982\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 35s 126us/step - loss: 0.5564 - acc: 0.8584 - val_loss: 0.9178 - val_acc: 0.7657\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5520 - acc: 0.8594 - val_loss: 0.7857 - val_acc: 0.8081\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 0.5457 - acc: 0.8613 - val_loss: 0.7844 - val_acc: 0.8060\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5421 - acc: 0.8620 - val_loss: 0.8171 - val_acc: 0.7929\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5370 - acc: 0.8628 - val_loss: 0.7896 - val_acc: 0.8035\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 36s 131us/step - loss: 0.5325 - acc: 0.8642 - val_loss: 0.8277 - val_acc: 0.7933\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 33s 119us/step - loss: 0.5317 - acc: 0.8654 - val_loss: 0.8114 - val_acc: 0.8007\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 35s 125us/step - loss: 0.5253 - acc: 0.8667 - val_loss: 0.7914 - val_acc: 0.8059\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 33s 119us/step - loss: 0.5209 - acc: 0.8669 - val_loss: 0.7872 - val_acc: 0.8064\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 35s 124us/step - loss: 0.5182 - acc: 0.8681 - val_loss: 0.8134 - val_acc: 0.7998\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5139 - acc: 0.8691 - val_loss: 0.8358 - val_acc: 0.7947\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.5112 - acc: 0.8700 - val_loss: 0.8037 - val_acc: 0.8033\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 35s 126us/step - loss: 0.5082 - acc: 0.8708 - val_loss: 0.8534 - val_acc: 0.7895\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 34s 122us/step - loss: 0.5050 - acc: 0.8715 - val_loss: 0.8079 - val_acc: 0.8051\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 37s 131us/step - loss: 0.5013 - acc: 0.8726 - val_loss: 0.8438 - val_acc: 0.7930\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.4985 - acc: 0.8734 - val_loss: 0.8039 - val_acc: 0.8051\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 36s 129us/step - loss: 0.4960 - acc: 0.8739 - val_loss: 0.8823 - val_acc: 0.7823\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 34s 121us/step - loss: 0.4936 - acc: 0.8747 - val_loss: 0.8116 - val_acc: 0.8036\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 33s 120us/step - loss: 0.4913 - acc: 0.8747 - val_loss: 0.7853 - val_acc: 0.8089\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 38s 136us/step - loss: 0.4875 - acc: 0.8755 - val_loss: 0.8788 - val_acc: 0.7833\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 34s 123us/step - loss: 0.4858 - acc: 0.8765 - val_loss: 0.8106 - val_acc: 0.8049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG6jcfYVWodc",
        "colab_type": "code",
        "outputId": "7c0f27c2-af37-4c0c-8b04-e389cb953d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(Embedding(10000, 20, input_length=100))\n",
        "lstm.add(LSTM(20))\n",
        "lstm.add(Dense(24, activation='softmax'))\n",
        "lstm.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_lstm = lstm.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 2.3753 - acc: 0.2826 - val_loss: 1.8009 - val_acc: 0.4638\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 1.4421 - acc: 0.6046 - val_loss: 1.2574 - val_acc: 0.6774\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 97s 348us/step - loss: 1.0113 - acc: 0.7463 - val_loss: 1.0323 - val_acc: 0.7310\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 95s 339us/step - loss: 0.8423 - acc: 0.7914 - val_loss: 0.8232 - val_acc: 0.7961\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.7486 - acc: 0.8128 - val_loss: 0.8623 - val_acc: 0.7755\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.6853 - acc: 0.8275 - val_loss: 0.7582 - val_acc: 0.8044\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.6417 - acc: 0.8363 - val_loss: 0.7155 - val_acc: 0.8179\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.6099 - acc: 0.8425 - val_loss: 0.6989 - val_acc: 0.8189\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 93s 336us/step - loss: 0.5844 - acc: 0.8481 - val_loss: 0.6596 - val_acc: 0.8304\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 95s 343us/step - loss: 0.5648 - acc: 0.8514 - val_loss: 0.6474 - val_acc: 0.8319\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 94s 336us/step - loss: 0.5475 - acc: 0.8553 - val_loss: 0.6315 - val_acc: 0.8362\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.5333 - acc: 0.8583 - val_loss: 0.6204 - val_acc: 0.8374\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 96s 346us/step - loss: 0.5205 - acc: 0.8608 - val_loss: 0.6131 - val_acc: 0.8399\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.5095 - acc: 0.8634 - val_loss: 0.6309 - val_acc: 0.8337\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4993 - acc: 0.8656 - val_loss: 0.6053 - val_acc: 0.8401\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 96s 345us/step - loss: 0.4896 - acc: 0.8675 - val_loss: 0.5920 - val_acc: 0.8448\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4806 - acc: 0.8695 - val_loss: 0.5930 - val_acc: 0.8432\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4732 - acc: 0.8711 - val_loss: 0.5796 - val_acc: 0.8471\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.4656 - acc: 0.8729 - val_loss: 0.5796 - val_acc: 0.8458\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 95s 342us/step - loss: 0.4587 - acc: 0.8746 - val_loss: 0.5883 - val_acc: 0.8444\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4524 - acc: 0.8759 - val_loss: 0.5742 - val_acc: 0.8474\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.4469 - acc: 0.8774 - val_loss: 0.5777 - val_acc: 0.8469\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.4410 - acc: 0.8786 - val_loss: 0.5634 - val_acc: 0.8497\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.4364 - acc: 0.8799 - val_loss: 0.5839 - val_acc: 0.8445\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 95s 341us/step - loss: 0.4315 - acc: 0.8809 - val_loss: 0.5635 - val_acc: 0.8501\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 96s 345us/step - loss: 0.4268 - acc: 0.8822 - val_loss: 0.5617 - val_acc: 0.8511\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4225 - acc: 0.8831 - val_loss: 0.5595 - val_acc: 0.8512\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.4181 - acc: 0.8844 - val_loss: 0.5659 - val_acc: 0.8502\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 96s 345us/step - loss: 0.4142 - acc: 0.8852 - val_loss: 0.5586 - val_acc: 0.8516\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 94s 339us/step - loss: 0.4107 - acc: 0.8859 - val_loss: 0.5714 - val_acc: 0.8481\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 95s 339us/step - loss: 0.4075 - acc: 0.8867 - val_loss: 0.5600 - val_acc: 0.8526\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.4037 - acc: 0.8876 - val_loss: 0.5621 - val_acc: 0.8502\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 96s 343us/step - loss: 0.4008 - acc: 0.8884 - val_loss: 0.5606 - val_acc: 0.8515\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3976 - acc: 0.8893 - val_loss: 0.5674 - val_acc: 0.8508\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 94s 336us/step - loss: 0.3943 - acc: 0.8903 - val_loss: 0.5682 - val_acc: 0.8505\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 97s 349us/step - loss: 0.3912 - acc: 0.8913 - val_loss: 0.5647 - val_acc: 0.8499\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3888 - acc: 0.8921 - val_loss: 0.5597 - val_acc: 0.8528\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3860 - acc: 0.8924 - val_loss: 0.5520 - val_acc: 0.8548\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 97s 347us/step - loss: 0.3834 - acc: 0.8933 - val_loss: 0.5577 - val_acc: 0.8541\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 94s 338us/step - loss: 0.3810 - acc: 0.8942 - val_loss: 0.5627 - val_acc: 0.8517\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 94s 336us/step - loss: 0.3787 - acc: 0.8945 - val_loss: 0.5635 - val_acc: 0.8520\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 96s 345us/step - loss: 0.3762 - acc: 0.8952 - val_loss: 0.5593 - val_acc: 0.8531\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 95s 340us/step - loss: 0.3736 - acc: 0.8959 - val_loss: 0.5596 - val_acc: 0.8539\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 93s 335us/step - loss: 0.3714 - acc: 0.8963 - val_loss: 0.5639 - val_acc: 0.8526\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 94s 339us/step - loss: 0.3696 - acc: 0.8968 - val_loss: 0.5637 - val_acc: 0.8519\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 94s 339us/step - loss: 0.3672 - acc: 0.8975 - val_loss: 0.5730 - val_acc: 0.8517\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 93s 334us/step - loss: 0.3651 - acc: 0.8983 - val_loss: 0.5592 - val_acc: 0.8538\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3632 - acc: 0.8985 - val_loss: 0.5677 - val_acc: 0.8518\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 94s 337us/step - loss: 0.3614 - acc: 0.8990 - val_loss: 0.5610 - val_acc: 0.8543\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 93s 333us/step - loss: 0.3595 - acc: 0.8997 - val_loss: 0.5632 - val_acc: 0.8528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMZUKF-qQv94",
        "colab_type": "code",
        "outputId": "e88b260b-4bff-410f-f31e-fe4e3d5b84f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "source": [
        "gru = Sequential()\n",
        "gru.add(Embedding(10000, 20, input_length=100))\n",
        "gru.add(GRU(20))\n",
        "gru.add(Dense(24, activation='softmax'))\n",
        "gru.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_gru = gru.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=50, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/50\n",
            "278612/278612 [==============================] - 83s 296us/step - loss: 2.5215 - acc: 0.2226 - val_loss: 2.1582 - val_acc: 0.3224\n",
            "Epoch 2/50\n",
            "278612/278612 [==============================] - 80s 288us/step - loss: 1.8757 - acc: 0.4462 - val_loss: 1.6292 - val_acc: 0.5709\n",
            "Epoch 3/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 1.3641 - acc: 0.6456 - val_loss: 1.1984 - val_acc: 0.7007\n",
            "Epoch 4/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 1.0539 - acc: 0.7408 - val_loss: 0.9840 - val_acc: 0.7619\n",
            "Epoch 5/50\n",
            "278612/278612 [==============================] - 81s 289us/step - loss: 0.8816 - acc: 0.7863 - val_loss: 0.8611 - val_acc: 0.7920\n",
            "Epoch 6/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.7751 - acc: 0.8096 - val_loss: 0.7780 - val_acc: 0.8089\n",
            "Epoch 7/50\n",
            "278612/278612 [==============================] - 79s 285us/step - loss: 0.7051 - acc: 0.8236 - val_loss: 0.7264 - val_acc: 0.8189\n",
            "Epoch 8/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.6546 - acc: 0.8330 - val_loss: 0.6934 - val_acc: 0.8250\n",
            "Epoch 9/50\n",
            "278612/278612 [==============================] - 81s 289us/step - loss: 0.6180 - acc: 0.8401 - val_loss: 0.6854 - val_acc: 0.8215\n",
            "Epoch 10/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.5885 - acc: 0.8464 - val_loss: 0.6505 - val_acc: 0.8319\n",
            "Epoch 11/50\n",
            "278612/278612 [==============================] - 79s 285us/step - loss: 0.5657 - acc: 0.8508 - val_loss: 0.6439 - val_acc: 0.8318\n",
            "Epoch 12/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.5456 - acc: 0.8554 - val_loss: 0.6225 - val_acc: 0.8371\n",
            "Epoch 13/50\n",
            "278612/278612 [==============================] - 80s 289us/step - loss: 0.5289 - acc: 0.8580 - val_loss: 0.6255 - val_acc: 0.8353\n",
            "Epoch 14/50\n",
            "278612/278612 [==============================] - 79s 285us/step - loss: 0.5145 - acc: 0.8612 - val_loss: 0.5956 - val_acc: 0.8424\n",
            "Epoch 15/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.5021 - acc: 0.8640 - val_loss: 0.5865 - val_acc: 0.8443\n",
            "Epoch 16/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.4901 - acc: 0.8661 - val_loss: 0.5780 - val_acc: 0.8445\n",
            "Epoch 17/50\n",
            "278612/278612 [==============================] - 80s 288us/step - loss: 0.4800 - acc: 0.8687 - val_loss: 0.5702 - val_acc: 0.8478\n",
            "Epoch 18/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.4707 - acc: 0.8705 - val_loss: 0.5691 - val_acc: 0.8475\n",
            "Epoch 19/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.4622 - acc: 0.8725 - val_loss: 0.5693 - val_acc: 0.8476\n",
            "Epoch 20/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.4544 - acc: 0.8741 - val_loss: 0.5667 - val_acc: 0.8485\n",
            "Epoch 21/50\n",
            "278612/278612 [==============================] - 80s 289us/step - loss: 0.4472 - acc: 0.8756 - val_loss: 0.5597 - val_acc: 0.8506\n",
            "Epoch 22/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.4407 - acc: 0.8775 - val_loss: 0.5618 - val_acc: 0.8504\n",
            "Epoch 23/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.4341 - acc: 0.8792 - val_loss: 0.5542 - val_acc: 0.8516\n",
            "Epoch 24/50\n",
            "278612/278612 [==============================] - 80s 289us/step - loss: 0.4284 - acc: 0.8808 - val_loss: 0.5533 - val_acc: 0.8525\n",
            "Epoch 25/50\n",
            "278612/278612 [==============================] - 80s 288us/step - loss: 0.4231 - acc: 0.8819 - val_loss: 0.5535 - val_acc: 0.8522\n",
            "Epoch 26/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.4178 - acc: 0.8837 - val_loss: 0.5504 - val_acc: 0.8524\n",
            "Epoch 27/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.4128 - acc: 0.8848 - val_loss: 0.5673 - val_acc: 0.8495\n",
            "Epoch 28/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.4086 - acc: 0.8864 - val_loss: 0.5534 - val_acc: 0.8538\n",
            "Epoch 29/50\n",
            "278612/278612 [==============================] - 81s 290us/step - loss: 0.4040 - acc: 0.8874 - val_loss: 0.5482 - val_acc: 0.8530\n",
            "Epoch 30/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.3997 - acc: 0.8884 - val_loss: 0.5487 - val_acc: 0.8545\n",
            "Epoch 31/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3960 - acc: 0.8895 - val_loss: 0.5565 - val_acc: 0.8517\n",
            "Epoch 32/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3921 - acc: 0.8908 - val_loss: 0.5586 - val_acc: 0.8528\n",
            "Epoch 33/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.3881 - acc: 0.8918 - val_loss: 0.5517 - val_acc: 0.8543\n",
            "Epoch 34/50\n",
            "278612/278612 [==============================] - 78s 281us/step - loss: 0.3847 - acc: 0.8926 - val_loss: 0.5507 - val_acc: 0.8548\n",
            "Epoch 35/50\n",
            "278612/278612 [==============================] - 79s 285us/step - loss: 0.3811 - acc: 0.8938 - val_loss: 0.5507 - val_acc: 0.8549\n",
            "Epoch 36/50\n",
            "278612/278612 [==============================] - 79s 283us/step - loss: 0.3782 - acc: 0.8944 - val_loss: 0.5507 - val_acc: 0.8539\n",
            "Epoch 37/50\n",
            "278612/278612 [==============================] - 80s 289us/step - loss: 0.3749 - acc: 0.8955 - val_loss: 0.5527 - val_acc: 0.8547\n",
            "Epoch 38/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3720 - acc: 0.8962 - val_loss: 0.5545 - val_acc: 0.8547\n",
            "Epoch 39/50\n",
            "278612/278612 [==============================] - 80s 287us/step - loss: 0.3690 - acc: 0.8972 - val_loss: 0.5549 - val_acc: 0.8551\n",
            "Epoch 40/50\n",
            "278612/278612 [==============================] - 80s 286us/step - loss: 0.3661 - acc: 0.8978 - val_loss: 0.5537 - val_acc: 0.8542\n",
            "Epoch 41/50\n",
            "278612/278612 [==============================] - 79s 284us/step - loss: 0.3634 - acc: 0.8988 - val_loss: 0.5611 - val_acc: 0.8532\n",
            "Epoch 42/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3609 - acc: 0.8996 - val_loss: 0.5577 - val_acc: 0.8546\n",
            "Epoch 43/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3586 - acc: 0.9003 - val_loss: 0.5560 - val_acc: 0.8553\n",
            "Epoch 44/50\n",
            "278612/278612 [==============================] - 83s 298us/step - loss: 0.3560 - acc: 0.9009 - val_loss: 0.5615 - val_acc: 0.8554\n",
            "Epoch 45/50\n",
            "278612/278612 [==============================] - 78s 282us/step - loss: 0.3534 - acc: 0.9017 - val_loss: 0.5607 - val_acc: 0.8550\n",
            "Epoch 46/50\n",
            "278612/278612 [==============================] - 77s 277us/step - loss: 0.3511 - acc: 0.9022 - val_loss: 0.5639 - val_acc: 0.8539\n",
            "Epoch 47/50\n",
            "278612/278612 [==============================] - 78s 280us/step - loss: 0.3491 - acc: 0.9031 - val_loss: 0.5569 - val_acc: 0.8551\n",
            "Epoch 48/50\n",
            "278612/278612 [==============================] - 79s 285us/step - loss: 0.3470 - acc: 0.9036 - val_loss: 0.5577 - val_acc: 0.8560\n",
            "Epoch 49/50\n",
            "278612/278612 [==============================] - 77s 278us/step - loss: 0.3445 - acc: 0.9040 - val_loss: 0.5686 - val_acc: 0.8541\n",
            "Epoch 50/50\n",
            "278612/278612 [==============================] - 79s 282us/step - loss: 0.3425 - acc: 0.9049 - val_loss: 0.5611 - val_acc: 0.8563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6olA85yWsyG",
        "colab_type": "code",
        "outputId": "cb10e9b9-8398-4271-c419-1bdbeb81c68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# 2-layers RNN \n",
        "rnn2 = Sequential()\n",
        "rnn2.add(Embedding(10000, 20, input_length=100))\n",
        "rnn2.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn2.add(SimpleRNN(20))\n",
        "rnn2.add(Dense(24, activation='softmax'))\n",
        "rnn2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn2 = rnn2.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 65s 235us/step - loss: 2.1602 - acc: 0.3415 - val_loss: 1.7978 - val_acc: 0.4542\n",
            "Epoch 2/20\n",
            "278612/278612 [==============================] - 65s 233us/step - loss: 1.6086 - acc: 0.5313 - val_loss: 1.5070 - val_acc: 0.5755\n",
            "Epoch 3/20\n",
            "278612/278612 [==============================] - 66s 237us/step - loss: 1.3777 - acc: 0.6203 - val_loss: 1.4648 - val_acc: 0.5905\n",
            "Epoch 4/20\n",
            "278612/278612 [==============================] - 65s 232us/step - loss: 1.2026 - acc: 0.6751 - val_loss: 1.2036 - val_acc: 0.6759\n",
            "Epoch 5/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 1.0638 - acc: 0.7183 - val_loss: 2.3102 - val_acc: 0.3800\n",
            "Epoch 6/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.9652 - acc: 0.7485 - val_loss: 1.0818 - val_acc: 0.7140\n",
            "Epoch 7/20\n",
            "278612/278612 [==============================] - 65s 235us/step - loss: 0.9042 - acc: 0.7664 - val_loss: 0.9923 - val_acc: 0.7430\n",
            "Epoch 8/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.8435 - acc: 0.7834 - val_loss: 0.9624 - val_acc: 0.7534\n",
            "Epoch 9/20\n",
            "278612/278612 [==============================] - 65s 232us/step - loss: 0.8020 - acc: 0.7944 - val_loss: 0.9666 - val_acc: 0.7494\n",
            "Epoch 10/20\n",
            "278612/278612 [==============================] - 64s 229us/step - loss: 0.7701 - acc: 0.8039 - val_loss: 1.0107 - val_acc: 0.7328\n",
            "Epoch 11/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.7478 - acc: 0.8093 - val_loss: 0.9796 - val_acc: 0.7496\n",
            "Epoch 12/20\n",
            "278612/278612 [==============================] - 66s 235us/step - loss: 0.7330 - acc: 0.8132 - val_loss: 0.8872 - val_acc: 0.7759\n",
            "Epoch 13/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.7191 - acc: 0.8162 - val_loss: 0.8673 - val_acc: 0.7818\n",
            "Epoch 14/20\n",
            "278612/278612 [==============================] - 64s 231us/step - loss: 0.6949 - acc: 0.8233 - val_loss: 1.0651 - val_acc: 0.7195\n",
            "Epoch 15/20\n",
            "278612/278612 [==============================] - 64s 230us/step - loss: 0.6771 - acc: 0.8278 - val_loss: 0.9057 - val_acc: 0.7696\n",
            "Epoch 16/20\n",
            "278612/278612 [==============================] - 64s 228us/step - loss: 0.6597 - acc: 0.8321 - val_loss: 0.8422 - val_acc: 0.7894\n",
            "Epoch 17/20\n",
            "278612/278612 [==============================] - 65s 234us/step - loss: 0.6442 - acc: 0.8359 - val_loss: 0.9550 - val_acc: 0.7530\n",
            "Epoch 18/20\n",
            "278612/278612 [==============================] - 64s 229us/step - loss: 0.6350 - acc: 0.8382 - val_loss: 0.8251 - val_acc: 0.7939\n",
            "Epoch 19/20\n",
            "278612/278612 [==============================] - 64s 228us/step - loss: 0.6238 - acc: 0.8411 - val_loss: 1.0189 - val_acc: 0.7356\n",
            "Epoch 20/20\n",
            "278612/278612 [==============================] - 63s 226us/step - loss: 0.6115 - acc: 0.8444 - val_loss: 0.9565 - val_acc: 0.7557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4my1qGI4wxM",
        "colab_type": "code",
        "outputId": "5c1e17ee-0dbc-4243-ae92-169eb8e0bdd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "# 4-layers RNN \n",
        "rnn4 = Sequential()\n",
        "rnn4.add(Embedding(10000, 20, input_length=100))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20, return_sequences=True))\n",
        "rnn4.add(SimpleRNN(20))\n",
        "rnn4.add(Dense(24, activation='softmax'))\n",
        "rnn4.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn4 = rnn4.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 278612 samples, validate on 69649 samples\n",
            "Epoch 1/20\n",
            "278612/278612 [==============================] - 125s 448us/step - loss: 2.2693 - acc: 0.3256 - val_loss: 1.8566 - val_acc: 0.4414\n",
            "Epoch 2/20\n",
            "238080/278612 [========================>.....] - ETA: 15s - loss: 1.4521 - acc: 0.5937"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ve8ratR45xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_drop = Sequential()\n",
        "rnn_drop.add(Embedding(10000, 20, input_length=100))\n",
        "rnn_drop.add(SimpleRNN(20, dropout=0.3))\n",
        "rnn_drop.add(Dense(24, activation='softmax'))\n",
        "rnn_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_rnn_drop = rnn_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3PQ9App4_C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm_drop = Sequential()\n",
        "lstm_drop.add(Embedding(10000, 20, input_length=100))\n",
        "lstm_drop.add(LSTM(20, dropout=0.3))\n",
        "lstm_drop.add(Dense(24, activation='softmax'))\n",
        "lstm_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_lstm_drop = lstm_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIiSNTmy5A_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_drop = Sequential()\n",
        "gru_drop.add(Embedding(10000, 20, input_length=100))\n",
        "gru_drop.add(GRU(20, dropout=0.3))\n",
        "gru_drop.add(Dense(24, activation='softmax'))\n",
        "gru_drop.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "result_gru_drop = gru_drop.fit(train_x, train_y, validation_data=(valid_x,valid_y), epochs=20, batch_size=512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipyQapwN5DhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_ff = result_ff.history['val_loss']\n",
        "loss_rnn1 = result_rnn.history['val_loss']\n",
        "loss_lstm = result_lstm.history['val_loss']\n",
        "loss_gru = result_gru.history['val_loss']\n",
        "loss_rnn2 = result_rnn2.history['val_loss']\n",
        "loss_rnn4 = result_rnn4.history['val_loss']\n",
        "loss_rnn_drop = result_rnn_drop.history['val_loss']\n",
        "loss_lstm_drop = result_lstm_drop.history['val_loss']\n",
        "loss_gru_drop = result_gru_drop.history['val_loss']\n",
        "plt.plot(loss_ff)\n",
        "plt.plot(loss_rnn1)\n",
        "plt.plot(loss_lstm)\n",
        "plt.plot(loss_gru)\n",
        "plt.plot(loss_rnn2)\n",
        "plt.plot(loss_rnn4)\n",
        "plt.plot(loss_rnn_drop)\n",
        "plt.plot(loss_lstm_drop)\n",
        "plt.plot(loss_gru_drop)\n",
        "plt.legend(['ff', 'rnn_1layer', 'lstm', 'gru', 'rnn_2layers', 'rnn_4layers', 'rnn_dropout', 'lstm_dropout', 'gru_dropout'])\n",
        "plt.title('Comparing validation set loss over the epochs')\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__y1VxRG5EFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_ff = result_ff.history['val_acc']\n",
        "acc_rnn1 = result_rnn.history['val_acc']\n",
        "acc_lstm = result_lstm.history['val_acc']\n",
        "acc_gru = result_gru.history['val_acc']\n",
        "acc_rnn2 = result_rnn2.history['val_acc']\n",
        "acc_rnn4 = result_rnn4.history['val_acc']\n",
        "acc_rnn_drop = result_rnn_drop.history['val_acc']\n",
        "acc_lstm_drop = result_lstm_drop.history['val_acc']\n",
        "acc_gru_drop = result_gru_drop.history['val_acc']\n",
        "plt.plot(acc_ff)\n",
        "plt.plot(acc_rnn1)\n",
        "plt.plot(acc_lstm)\n",
        "plt.plot(acc_gru)\n",
        "plt.plot(acc_rnn2)\n",
        "plt.plot(acc_rnn4)\n",
        "plt.plot(acc_rnn_drop)\n",
        "plt.plot(acc_lstm_drop)\n",
        "plt.plot(acc_gru_drop)\n",
        "plt.legend(['ff', 'rnn_1layer', 'lstm', 'gru', 'rnn_2layers', 'rnn_4layers', 'rnn_dropout', 'lstm_dropout', 'gru_dropout'])\n",
        "plt.title(\"Comparing validation set accuracy over the epochs\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THi-X-FO5Jqm",
        "colab_type": "text"
      },
      "source": [
        "The best performing model is LSTM."
      ]
    }
  ]
}